{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://arxiv.org/pdf/1503.02531.pdf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Knowledge Distillation "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[TODO] write introduction for knowledge distillation\n",
        "[TODO] Add relevant references at the end of the notebook"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Knowledge Distillation exactly?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In this tutorial\n",
        "\n",
        "- [Setup](#Setup)\n",
        "- [Functions](#Functions)\n",
        "- [Data](#load-data)\n",
        "- [Experiments](#experiments)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Using cached split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1685986535493
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import PIL\n",
        "from sklearn.model_selection import train_test_split\n",
        "import splitfolders\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1685986535635
        }
      },
      "outputs": [],
      "source": [
        "drop_rate = 0\n",
        "train_val_test_split = (0.7,0.2,0.1)\n",
        "batch_size = 96\n",
        "num_workers=6\n",
        "drop_rate = 0.23\n",
        "train_dir = '../data/train'\n",
        "epochs = 10\n",
        "lr = 0.001"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_size(model):\n",
        "    \"\"\"function to calculate the model size in MB\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): pytorch model\n",
        "    \"\"\"\n",
        "    param_size = 0\n",
        "    for param in model.parameters():\n",
        "        param_size += param.nelement() * param.element_size()\n",
        "    \n",
        "    buffer_size = 0\n",
        "    for buffer in model.buffers():\n",
        "        buffer_size += buffer.nelement() * buffer.element_size()\n",
        "    \n",
        "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "\n",
        "    return size_all_mb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for X, y in tqdm.tqdm(dataloader, desc = \"Training\", unit = \" Iterations\"):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #if batch % 100 == 0:\n",
        "        #    loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        #    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm.tqdm(dataloader, desc = \"Validating\", unit=\"Iterations\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DistillationLoss:\n",
        "\n",
        "    \"\"\"Custom loss calculcation combining\n",
        "    the loss of the student model with the distillation loss\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, student_loss, temperature=1, alpha=0.25):\n",
        "        self.student_loss = student_loss\n",
        "        self.temperature = 1\n",
        "        self.alpha = 0.25\n",
        "\n",
        "    def __call__(self, student_logits, student_target_loss, teacher_logits):\n",
        "        distillation_loss = nn.KLDivLoss(\n",
        "            F.log_softmax(student_logits / self.temperature, dim=1),\n",
        "            F.softmax(teacher_logits/self.temperature, dim=1))\n",
        "        loss = (1 - self.alpha) * student_target_loss \\\n",
        "            + self.alpha * distillation_loss\n",
        "        return loss\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Student/Teacher Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1685986535741
        }
      },
      "outputs": [],
      "source": [
        "class Teacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = torchvision.models.densenet201(weights='DEFAULT')\n",
        "        for params in self.model.parameters():\n",
        "            params.requires_grad_ = False\n",
        "\n",
        "        num_ftrs = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Sequential(\n",
        "            nn.Linear(num_ftrs, 500),\n",
        "            nn.Linear(500, 2)\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1685986535848
        }
      },
      "outputs": [],
      "source": [
        "class Student(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # onvolutional layers (3,16,32)\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size=(5, 5), stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size=(5, 5), stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=(3, 3), padding=1)\n",
        "\n",
        "        # conected layers\n",
        "        self.fc1 = nn.Linear(in_features= 64 * 3 * 3, out_features=500)\n",
        "        self.fc2 = nn.Linear(in_features=500, out_features=50)\n",
        "        self.fc3 = nn.Linear(in_features=50, out_features=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Cats&Dogs Dataset; Unzip the dataset\n",
        "#!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
        "#!unzip -q kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1685986536403
        }
      },
      "outputs": [],
      "source": [
        "data_dir = './PetImages/'\n",
        "#files = [f for f in os.listdir(data_dir) if '.jpg' in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#splitfolders.ratio(data_dir, output=\"output\", ratio=train_val_test_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1685986536531
        }
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dir = './output/train/'\n",
        "val_dir = './output/val/'\n",
        "test_dir = './output/test/'\n",
        "\n",
        "train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
        "val_dataset = ImageFolder(val_dir, transform=val_transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=val_transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True, num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1685986536648
        }
      },
      "outputs": [],
      "source": [
        "# Creating dataset\n",
        "\n",
        "class DogsVsCatsDataset(Dataset):\n",
        "    def __init__(self, file_list, dir, mode='train', transform = val_transform):\n",
        "        self.file_list = file_list\n",
        "        self.dir = dir\n",
        "        self.mode= mode\n",
        "        self.transform = transform\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = PIL.Image.open(os.path.join(self.dir, self.file_list[idx]))\n",
        "        img = self.transform(img)\n",
        "        img = np.array(img)\n",
        "        if 'dog' in self.file_list[idx]:\n",
        "            self.label = 1\n",
        "        else:\n",
        "            self.label = 0\n",
        "        return img.astype('float32'), self.label\n",
        "\n",
        "\n",
        "train_files, test_files = train_test_split(train_files, \n",
        "                                    test_size=train_val_test_split[2], \n",
        "                                    random_state=42\n",
        "                                    )\n",
        "train_files, valid_files = train_test_split(train_files,\n",
        "                                    test_size=train_val_test_split[1]/train_val_test_split[0], \n",
        "                                    random_state=42\n",
        "                                    )\n",
        "\n",
        "TrainDataSet = DogsVsCatsDataset(train_files, dir = train_dir, mode='train', transform = train_transform)\n",
        "TrainDataLoader = DataLoader(TrainDataSet, batch_size = batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "ValidDataSet = DogsVsCatsDataset(valid_files, dir = train_dir, mode='valid')\n",
        "ValidDataLoader = DataLoader(ValidDataSet, batch_size = batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "TestDataSet = DogsVsCatsDataset(test_files, dir = train_dir, mode='test')\n",
        "TestDataLoader = DataLoader(TestDataSet, batch_size = batch_size, shuffle=False, num_workers=num_workers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1685986536771
        }
      },
      "outputs": [],
      "source": [
        "student_model = Student()\n",
        "teacher_model = Teacher()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model size teachermodel : 73.562MB\n",
            "model size student model: 1.321MB\n"
          ]
        }
      ],
      "source": [
        "model_size_student = get_model_size(student_model)\n",
        "model_size_teacher = get_model_size(teacher_model)\n",
        "\n",
        "print('model size teachermodel : {:.3f}MB'.format(model_size_teacher))\n",
        "print('model size student model: {:.3f}MB'.format(model_size_student))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "gather": {
          "logged": 1685986536872
        }
      },
      "source": [
        "def train(model):\n",
        "\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    valid_loss_list = []\n",
        "    valid_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch\",epoch+1,\"/\",epochs)\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        itr = 1\n",
        "        tot_itr = len(TrainDataLoader)\n",
        "        for samples, labels in tqdm.tqdm(TrainDataLoader, desc = \"Training\", unit = \" Iterations\"):\n",
        "            samples, labels = samples.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(samples)\n",
        "            loss = criterion(output, labels)\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            correct = pred.eq(labels)\n",
        "            train_acc+= torch.mean(correct.float())\n",
        "            torch.cuda.empty_cache()\n",
        "            itr += 1\n",
        "            \n",
        "        train_loss_list.append(train_loss/tot_itr)\n",
        "        train_acc_list.append(train_acc.item()/tot_itr)\n",
        "        print(' Total Loss: {:.4f}, Accuracy: {:.1f} %'.format(train_loss, train_acc/tot_itr*100))\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss=0\n",
        "        valid_acc=0\n",
        "        itr=1\n",
        "        tot_itr = len(ValidDataLoader)\n",
        "        for samples, labels in tqdm.tqdm(ValidDataLoader, desc = \"Validating\", unit = \" Iterations\"):\n",
        "            with torch.no_grad():\n",
        "                samples, labels = samples.to(device), labels.to(device)\n",
        "                output = model(samples)\n",
        "                loss = criterion(output, labels)\n",
        "                valid_loss += loss.item()\n",
        "                pred = torch.argmax(output, dim=1)\n",
        "                correct = pred.eq(labels)\n",
        "                valid_acc += torch.mean(correct.float())\n",
        "                torch.cuda.empty_cache()\n",
        "                itr += 1\n",
        "                \n",
        "        valid_loss_list.append(valid_loss/tot_itr)\n",
        "        valid_acc_list.append(valid_acc.item()/tot_itr)\n",
        "        print('-----------------------------> Validation Loss: {:.4f}, Accuracy: {:.1f} %'.format(valid_loss, valid_acc/tot_itr*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Teacher model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1685987854779
        }
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(teacher_model.parameters(), lr=lr, amsgrad=True)\n",
        "teacher_model = teacher_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 0/183 [00:00<?, ? Iterations/s]Bad pipe message: %s [b'r\\xda\\x0b\\xceC\\x1bm\\x15\\x1ac\\xc2\\x10\\x18\\x99\\x0e\\xe2Y\\xa8\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0', b\"$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\"]\n",
            "Bad pipe message: %s [b'\\xddk6{\\xad;,\\xdb\\xe8\\x07d\\x96/\\xf0d\\x11']\n",
            "Bad pipe message: %s [b'N\\xb1\\x9e.\\x0b\\xe7~\\xd2\\xe1\\xcfoM\\xe4/\\x16:#\\xc4\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c']\n",
            "Bad pipe message: %s [b'\\x18\\x86l\\xe6c{\\x0c\\x0b\\xdf\\xb7.\\xd6\\x9c\\x1d\\xfb\\x14!l\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00', b'F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t']\n",
            "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n",
            "Training:  45%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 82/183 [01:34<01:55,  1.15s/ Iterations]\n"
          ]
        },
        {
          "ename": "UnidentifiedImageError",
          "evalue": "Caught UnidentifiedImageError in DataLoader worker process 4.\nOriginal Traceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 230, in __getitem__\n    sample = self.loader(path)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 269, in default_loader\n    return pil_loader(path)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 248, in pil_loader\n    img = Image.open(f)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/PIL/Image.py\", line 2967, in open\n    raise UnidentifiedImageError(\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='./output/train/Cat/666.jpg'>\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     train(train_dataloader, teacher_model, loss_fn\u001b[39m=\u001b[39;49mcriterion, optimizer\u001b[39m=\u001b[39;49moptimizer)\n\u001b[1;32m      6\u001b[0m     test(val_dataloader, teacher_model, loss_fn\u001b[39m=\u001b[39mcriterion)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(dataloader, desc \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTraining\u001b[39m\u001b[39m\"\u001b[39m, unit \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m Iterations\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Compute prediction error\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx]) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1326\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx)[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1327\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1330\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1373\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1373\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1374\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
            "\u001b[0;31mUnidentifiedImageError\u001b[0m: Caught UnidentifiedImageError in DataLoader worker process 4.\nOriginal Traceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 230, in __getitem__\n    sample = self.loader(path)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 269, in default_loader\n    return pil_loader(path)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torchvision/datasets/folder.py\", line 248, in pil_loader\n    img = Image.open(f)\n  File \"/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/PIL/Image.py\", line 2967, in open\n    raise UnidentifiedImageError(\nPIL.UnidentifiedImageError: cannot identify image file <_io.BufferedReader name='./output/train/Cat/666.jpg'>\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune the final classification layers of the teacher model\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, teacher_model, loss_fn=criterion, optimizer=optimizer)\n",
        "    test(val_dataloader, teacher_model, loss_fn=criterion)\n",
        "print(\"Done!\")\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Student Model from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1685989182796
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 10\n",
            " Total Loss: 90.5205, Accuracy: 56.7 %\n",
            "-----------------------------> Validation Loss: 37.1146, Accuracy: 57.0 %\n",
            "Epoch 2 / 10\n",
            " Total Loss: 85.4250, Accuracy: 63.6 %\n",
            "-----------------------------> Validation Loss: 36.2891, Accuracy: 59.5 %\n",
            "Epoch 3 / 10\n",
            " Total Loss: 81.3723, Accuracy: 67.3 %\n",
            "-----------------------------> Validation Loss: 31.9461, Accuracy: 69.3 %\n",
            "Epoch 4 / 10\n",
            " Total Loss: 78.0509, Accuracy: 69.2 %\n",
            "-----------------------------> Validation Loss: 29.9043, Accuracy: 71.4 %\n",
            "Epoch 5 / 10\n",
            " Total Loss: 71.9816, Accuracy: 72.7 %\n",
            "-----------------------------> Validation Loss: 29.7169, Accuracy: 72.1 %\n",
            "Epoch 6 / 10\n",
            " Total Loss: 68.4196, Accuracy: 75.0 %\n",
            "-----------------------------> Validation Loss: 28.2762, Accuracy: 74.7 %\n",
            "Epoch 7 / 10\n",
            " Total Loss: 65.8942, Accuracy: 76.2 %\n",
            "-----------------------------> Validation Loss: 26.3024, Accuracy: 76.5 %\n",
            "Epoch 8 / 10\n",
            " Total Loss: 64.1505, Accuracy: 76.8 %\n",
            "-----------------------------> Validation Loss: 24.9781, Accuracy: 78.5 %\n",
            "Epoch 9 / 10\n",
            " Total Loss: 61.7051, Accuracy: 78.3 %\n",
            "-----------------------------> Validation Loss: 25.2193, Accuracy: 77.8 %\n",
            "Epoch 10 / 10\n",
            " Total Loss: 61.6407, Accuracy: 77.8 %\n",
            "-----------------------------> Validation Loss: 27.1139, Accuracy: 75.6 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 134/134 [01:36<00:00,  1.39 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.44 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.41 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.46 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:36<00:00,  1.39 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.45 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.40 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.46 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.40 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.43 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.41 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.45 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.41 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.47 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.40 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.44 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:34<00:00,  1.42 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:38<00:00,  1.41 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:34<00:00,  1.42 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.45 Iterations/s]\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(student_model.parameters(), lr=lr, amsgrad=True)\n",
        "student_model = student_model.to(device)\n",
        "train(student_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Student Model with Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1685989182978
        }
      },
      "outputs": [],
      "source": [
        "student_model_distilled = Student()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1685989183118
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1685989183312
        }
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "ds_loss = DistillationLoss()\n",
        "optimizer = torch.optim.Adam(student_model_distilled.parameters(), lr=lr, amsgrad=True)\n",
        "teacher_model = teacher_model.to(device)\n",
        "student_model_distilled = student_model_distilled.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1685989183442
        }
      },
      "outputs": [],
      "source": [
        "def train_with_distillation(student_model, teacher_model):\n",
        "\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    valid_loss_list = []\n",
        "    valid_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"Epoch\",epoch+1,\"/\",epochs)\n",
        "        student_model.train()\n",
        "        teacher_model.eval()\n",
        "\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        \n",
        "        itr = 1\n",
        "        tot_itr = len(TrainDataLoader)\n",
        "        for samples, labels in tqdm.tqdm(TrainDataLoader, desc = \"Training\", unit = \" Iterations\"):\n",
        "            samples, labels = samples.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output_student = student_model(samples)\n",
        "            output_teacher = teacher_model(samples)\n",
        "\n",
        "            student_target_loss = criterion(output_student, labels)\n",
        "            loss = ds_loss(output_student, student_target_loss, output_teacher)\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pred = torch.argmax(output_student, dim=1)\n",
        "            correct = pred.eq(labels)\n",
        "            train_acc+= torch.mean(correct.float())\n",
        "            torch.cuda.empty_cache()\n",
        "            itr += 1\n",
        "            \n",
        "        train_loss_list.append(train_loss/tot_itr)\n",
        "        train_acc_list.append(train_acc.item()/tot_itr)\n",
        "        print(' Total Loss: {:.4f}, Accuracy: {:.1f} %'.format(train_loss, train_acc/tot_itr*100))\n",
        "\n",
        "        student_model.eval()\n",
        "        valid_loss=0\n",
        "        valid_acc=0\n",
        "        itr=1\n",
        "        tot_itr = len(ValidDataLoader)\n",
        "        for samples, labels in tqdm.tqdm(ValidDataLoader, desc = \"Validating\", unit = \" Iterations\"):\n",
        "            with torch.no_grad():\n",
        "                samples, labels = samples.to(device), labels.to(device)\n",
        "                output = student_model(samples)\n",
        "                loss = criterion(output, labels)\n",
        "                valid_loss += loss.item()\n",
        "                pred = torch.argmax(output, dim=1)\n",
        "                correct = pred.eq(labels)\n",
        "                valid_acc += torch.mean(correct.float())\n",
        "                torch.cuda.empty_cache()\n",
        "                itr += 1\n",
        "                \n",
        "        valid_loss_list.append(valid_loss/tot_itr)\n",
        "        valid_acc_list.append(valid_acc.item()/tot_itr)\n",
        "        print('-----------------------------> Validation Loss: {:.4f}, Accuracy: {:.1f} %'.format(valid_loss, valid_acc/tot_itr*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1685990490276
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 10\n",
            " Total Loss: 78.9578, Accuracy: 55.2 %\n",
            "-----------------------------> Validation Loss: 37.6149, Accuracy: 57.5 %\n",
            "Epoch 2 / 10\n",
            " Total Loss: 71.9161, Accuracy: 65.7 %\n",
            "-----------------------------> Validation Loss: 34.4853, Accuracy: 63.6 %\n",
            "Epoch 3 / 10\n",
            " Total Loss: 67.2270, Accuracy: 69.4 %\n",
            "-----------------------------> Validation Loss: 30.0797, Accuracy: 71.4 %\n",
            "Epoch 4 / 10\n",
            " Total Loss: 62.5051, Accuracy: 72.8 %\n",
            "-----------------------------> Validation Loss: 30.3225, Accuracy: 71.5 %\n",
            "Epoch 5 / 10\n",
            " Total Loss: 60.0720, Accuracy: 74.5 %\n",
            "-----------------------------> Validation Loss: 27.9254, Accuracy: 74.9 %\n",
            "Epoch 6 / 10\n",
            " Total Loss: 56.2233, Accuracy: 76.3 %\n",
            "-----------------------------> Validation Loss: 27.6159, Accuracy: 75.3 %\n",
            "Epoch 7 / 10\n",
            " Total Loss: 55.2416, Accuracy: 77.1 %\n",
            "-----------------------------> Validation Loss: 25.5862, Accuracy: 77.9 %\n",
            "Epoch 8 / 10\n",
            " Total Loss: 52.4742, Accuracy: 78.8 %\n",
            "-----------------------------> Validation Loss: 24.7130, Accuracy: 78.5 %\n",
            "Epoch 9 / 10\n",
            " Total Loss: 50.9153, Accuracy: 79.1 %\n",
            "-----------------------------> Validation Loss: 23.5063, Accuracy: 79.6 %\n",
            "Epoch 10 / 10\n",
            " Total Loss: 48.5994, Accuracy: 80.6 %\n",
            "-----------------------------> Validation Loss: 23.0932, Accuracy: 80.1 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/134 [00:00<?, ? Iterations/s]/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/functional.py:2904: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 134/134 [01:34<00:00,  1.42 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.45 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.41 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.49 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:33<00:00,  1.44 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.48 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:33<00:00,  1.44 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.49 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:32<00:00,  1.45 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.46 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:34<00:00,  1.42 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:37<00:00,  1.46 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:35<00:00,  1.41 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.47 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:33<00:00,  1.44 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.49 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:34<00:00,  1.42 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.48 Iterations/s]\n",
            "Training: 100%|██████████| 134/134 [01:34<00:00,  1.41 Iterations/s]\n",
            "Validating: 100%|██████████| 54/54 [00:36<00:00,  1.48 Iterations/s]\n"
          ]
        }
      ],
      "source": [
        "train_with_distillation(student_model=student_model_distilled, teacher_model=teacher_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1685990491358
        }
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1685990506439
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 79.7%, Avg loss: 0.443518 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test(TestDataLoader, student_model_distilled, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1685990519970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 74.7%, Avg loss: 0.524062 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test(TestDataLoader, student_model, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1685990536489
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Error: \n",
            " Accuracy: 95.9%, Avg loss: 0.132754 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "test(TestDataLoader, teacher_model, criterion)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# References "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "azureml_py38_PT_TF",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
